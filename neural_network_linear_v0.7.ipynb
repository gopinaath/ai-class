{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Neural Networks: Learn from Dataset\n",
        "\n",
        "This notebook teaches a neural network to learn a linear function using a pre-generated CSV dataset.\n",
        "\n",
        "We'll:\n",
        "- Load training and test datasets from CSV files\n",
        "- Build a simple model\n",
        "- Train using the dataset\n",
        "- Evaluate performance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "print(torch.__version__)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load the dataset\n",
        "First, we need to generate the dataset if it doesn't exist.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load datasets from GitHub repository\n",
        "import requests\n",
        "import io\n",
        "import os\n",
        "\n",
        "# GitHub repository URLs for the CSV files\n",
        "github_base_url = \"https://raw.githubusercontent.com/gopinaath/ai-class/main/\"\n",
        "train_url = github_base_url + \"linear_train.csv\"\n",
        "test_url = github_base_url + \"linear_test.csv\"\n",
        "\n",
        "print(\"Loading datasets from GitHub repository...\")\n",
        "print(f\"Training data URL: {train_url}\")\n",
        "print(f\"Test data URL: {test_url}\")\n",
        "\n",
        "try:\n",
        "    # Download and load training data\n",
        "    train_response = requests.get(train_url)\n",
        "    train_response.raise_for_status()  # Raise an exception for bad status codes\n",
        "    train_df = pd.read_csv(io.StringIO(train_response.text))\n",
        "\n",
        "    # Download and load test data\n",
        "    test_response = requests.get(test_url)\n",
        "    test_response.raise_for_status()\n",
        "    test_df = pd.read_csv(io.StringIO(test_response.text))\n",
        "\n",
        "    print(\"‚úÖ Datasets loaded successfully from GitHub!\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Failed to load from GitHub: {e}\")\n",
        "    print(\"üîÑ Falling back to local dataset generation...\")\n",
        "    \n",
        "    # Fallback: generate datasets locally\n",
        "    if not os.path.exists('linear_train.csv'):\n",
        "        exec(open('generate_linear_dataset.py').read())\n",
        "    \n",
        "    train_df = pd.read_csv('linear_train.csv')\n",
        "    test_df = pd.read_csv('linear_test.csv')\n",
        "    print(\"‚úÖ Local datasets loaded successfully!\")\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "train_inputs = torch.tensor(train_df[['a', 'b']].values, dtype=torch.float32)\n",
        "train_targets = torch.tensor(train_df['target'].values, dtype=torch.float32).unsqueeze(1)\n",
        "test_inputs = torch.tensor(test_df[['a', 'b']].values, dtype=torch.float32)\n",
        "test_targets = torch.tensor(test_df['target'].values, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "print(f\"Training data shape: {train_inputs.shape}\")\n",
        "print(f\"Test data shape: {test_inputs.shape}\")\n",
        "print(f\"First few training examples:\")\n",
        "print(train_df.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exploratory Data Analysis\n",
        "Let's explore our dataset to understand what we're working with.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Basic statistics\n",
        "print(\"=== Dataset Overview ===\")\n",
        "print(f\"Training samples: {len(train_df)}\")\n",
        "print(f\"Test samples: {len(test_df)}\")\n",
        "print(f\"Features: {list(train_df.columns[:-1])}\")  # All columns except 'target'\n",
        "print(f\"Target: {train_df.columns[-1]}\")\n",
        "\n",
        "print(\"\\n=== Training Data Statistics ===\")\n",
        "print(train_df.describe())\n",
        "\n",
        "print(\"\\n=== Test Data Statistics ===\")\n",
        "print(test_df.describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize the data\n",
        "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
        "\n",
        "# 1. Distribution of inputs\n",
        "axes[0, 0].hist(train_df['a'], bins=30, alpha=0.7, label='a', color='blue')\n",
        "axes[0, 0].hist(train_df['b'], bins=30, alpha=0.7, label='b', color='red')\n",
        "axes[0, 0].set_title('Distribution of Input Features')\n",
        "axes[0, 0].set_xlabel('Value')\n",
        "axes[0, 0].set_ylabel('Frequency')\n",
        "axes[0, 0].legend()\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# 2. Distribution of target\n",
        "axes[0, 1].hist(train_df['target'], bins=30, alpha=0.7, color='green')\n",
        "axes[0, 1].set_title('Distribution of Target Values')\n",
        "axes[0, 1].set_xlabel('Target Value')\n",
        "axes[0, 1].set_ylabel('Frequency')\n",
        "axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "# 3. Scatter plot: a vs target\n",
        "axes[1, 0].scatter(train_df['a'], train_df['target'], alpha=0.6, s=10)\n",
        "axes[1, 0].set_title('Feature a vs Target')\n",
        "axes[1, 0].set_xlabel('Feature a')\n",
        "axes[1, 0].set_ylabel('Target')\n",
        "axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# 4. Scatter plot: b vs target\n",
        "axes[1, 1].scatter(train_df['b'], train_df['target'], alpha=0.6, s=10, color='red')\n",
        "axes[1, 1].set_title('Feature b vs Target')\n",
        "axes[1, 1].set_xlabel('Feature b')\n",
        "axes[1, 1].set_ylabel('Target')\n",
        "axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check for correlations\n",
        "print(\"=== Correlation Analysis ===\")\n",
        "correlation_matrix = train_df.corr()\n",
        "print(correlation_matrix)\n",
        "\n",
        "# Visualize correlation heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.imshow(correlation_matrix, cmap='coolwarm', aspect='auto')\n",
        "plt.colorbar()\n",
        "plt.xticks(range(len(correlation_matrix.columns)), correlation_matrix.columns)\n",
        "plt.yticks(range(len(correlation_matrix.columns)), correlation_matrix.columns)\n",
        "\n",
        "# Add correlation values to the heatmap\n",
        "for i in range(len(correlation_matrix.columns)):\n",
        "    for j in range(len(correlation_matrix.columns)):\n",
        "        plt.text(j, i, f'{correlation_matrix.iloc[i, j]:.3f}', \n",
        "                ha='center', va='center', color='black', fontweight='bold')\n",
        "\n",
        "plt.title('Correlation Matrix')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Show some sample data\n",
        "print(\"\\n=== Sample Data ===\")\n",
        "print(\"First 10 training examples:\")\n",
        "print(train_df.head(10))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Key Insights from EDA\n",
        "\n",
        "**What we learned:**\n",
        "- **Input range**: Both `a` and `b` are uniformly distributed between 0 and 1\n",
        "- **Target range**: Target values range from ~0 to ~7 (since max is 3√ó1 + 4√ó1 = 7)\n",
        "- **Linear relationship**: We can see clear linear patterns in the scatter plots\n",
        "- **Correlations**: \n",
        "  - `a` has strong positive correlation with target (‚âà0.87)\n",
        "  - `b` has strong positive correlation with target (‚âà0.50)\n",
        "  - This makes sense since target = 3a + 4b (a has coefficient 3, b has coefficient 4)\n",
        "\n",
        "**Why this is good for neural networks:**\n",
        "- Clear linear relationship means a simple model should work well\n",
        "- No missing values or outliers to worry about\n",
        "- Good range of values for training\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Build the model\n",
        "A simple linear layer can learn any linear function.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = nn.Sequential(nn.Linear(2, 1))\n",
        "model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train the model\n",
        "We'll train using the entire dataset with mini-batches.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "loss_history = []\n",
        "\n",
        "batch_size = 32\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    epoch_loss = 0\n",
        "    num_batches = 0\n",
        "    \n",
        "    # Process data in mini-batches\n",
        "    for i in range(0, len(train_inputs), batch_size):\n",
        "        batch_inputs = train_inputs[i:i+batch_size]\n",
        "        batch_targets = train_targets[i:i+batch_size]\n",
        "        \n",
        "        # Forward pass\n",
        "        outputs = model(batch_inputs)\n",
        "        loss = criterion(outputs, batch_targets)\n",
        "        \n",
        "        # Backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        num_batches += 1\n",
        "        loss_history.append(loss.item())\n",
        "    \n",
        "    avg_loss = epoch_loss / num_batches\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Average Loss: {avg_loss:.6f}\")\n",
        "\n",
        "print(\"Training complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(loss_history)\n",
        "plt.title('Training Loss')\n",
        "plt.xlabel('Batch')\n",
        "plt.ylabel('MSE Loss')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "# Plot every 10th point to reduce noise\n",
        "plt.plot(loss_history[::10])\n",
        "plt.title('Training Loss (Every 10th Batch)')\n",
        "plt.xlabel('Batch (x10)')\n",
        "plt.ylabel('MSE Loss')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluate the model\n",
        "Test the model on the test dataset and some specific examples.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test on the test dataset\n",
        "with torch.no_grad():\n",
        "    test_outputs = model(test_inputs)\n",
        "    test_loss = criterion(test_outputs, test_targets)\n",
        "    \n",
        "print(f\"Test Loss: {test_loss.item():.6f}\")\n",
        "\n",
        "# Test on specific examples\n",
        "test_cases = [(1.0, 1.0), (2.0, -1.0), (0.5, 0.5), (-1.0, 2.0)]\n",
        "\n",
        "print(\"\\nTesting on specific examples:\")\n",
        "print(\"Input (a, b) | Prediction | Expected | Error\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "for a, b in test_cases:\n",
        "    pred = model(torch.tensor([a, b], dtype=torch.float32))\n",
        "    expected = 3*a + 4*b  # The actual function\n",
        "    error = abs(pred.item() - expected)\n",
        "    print(f\"({a:4.1f}, {b:4.1f})    | {pred.item():8.3f} | {expected:7.3f} | {error:.3f}\")\n",
        "\n",
        "# Show learned weights\n",
        "print(f\"\\nLearned weights:\")\n",
        "print(f\"Weight for 'a': {model[0].weight[0, 0].item():.3f}\")\n",
        "print(f\"Weight for 'b': {model[0].weight[0, 1].item():.3f}\")\n",
        "print(f\"Bias: {model[0].bias[0].item():.3f}\")\n",
        "print(f\"\\nExpected weights: a=3.0, b=4.0, bias=0.0\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
