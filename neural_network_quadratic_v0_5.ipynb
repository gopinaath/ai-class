{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Neural Networks: Learn a Quadratic Relationship\n",
        "\n",
        "We will teach a small neural network to approximate a quadratic function of two inputs.\n",
        "\n",
        "Steps:\n",
        "- Setup (import libraries)\n",
        "- Define the target quadratic function\n",
        "- Build a small non-linear model\n",
        "- Train the model\n",
        "- Evaluate with test cases\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "print(torch.__version__)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define the target quadratic function\n",
        "We'll use `f(a, b) = 2a^2 + 3b + 1`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def mystery(a, b):\n",
        "    # f(a, b) = 2a^2 + 3b + 1\n",
        "    return torch.tensor(2*a*a + 3*b + 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Linear(2, 20),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(20, 20),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(20, 10),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(10, 1)\n",
        ")\n",
        "model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train the model\n",
        "We sample `(a, b)` from [-2, 2] and optimize with Adam.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_history = []\n",
        "\n",
        "for i in range(100000):\n",
        "    a = random.uniform(-2, 2)\n",
        "    b = random.uniform(-2, 2)\n",
        "    desired = mystery(a, b)\n",
        "\n",
        "    output = model(torch.tensor([a, b], dtype=torch.float32))\n",
        "    loss = criterion(output.squeeze(), desired)\n",
        "    loss_history.append(loss.item())\n",
        "\n",
        "    if i % 5000 == 0:\n",
        "        print(f\"Loss: {loss.item():.6f}\")\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(6,4))\n",
        "plt.plot(loss_history)\n",
        "plt.title('Training Loss')\n",
        "plt.xlabel('Step')\n",
        "plt.ylabel('MSE Loss')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluate on sample inputs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_cases = [(1.0, 1.0), (2.0, -1.0), (0.5, 0.5), (-1.0, 2.0)]\n",
        "\n",
        "print(\"\\nTesting the trained neural network:\")\n",
        "print(\"Input (a, b) | Neural Network Output | Expected Output | Error\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "for a, b in test_cases:\n",
        "    output = model(torch.tensor([a, b], dtype=torch.float32))\n",
        "    expected = mystery(a, b)\n",
        "    error = abs(output.item() - expected.item())\n",
        "    print(f\"({a:4.1f}, {b:4.1f})    | {output.item():15.6f} | {expected.item():13.6f} | {error:.6f}\")\n",
        "\n",
        "print(f\"\\nFinal test - Input (1.0, 1.0):\")\n",
        "print(f\"Neural Network Output: {model(torch.tensor([1.0, 1.0], dtype=torch.float32)).item()}\")\n",
        "print(f\"Expected Output: {mystery(1.0, 1.0).item()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Build a non-linear model\n",
        "We use a few layers with ReLU activation to learn non-linear patterns.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
